#### 神经拟态模拟器

与传统的人工神经网络（如前馈神经网络和卷积神经网络）相比，SNN能够更高效地处理时间动态信息，理论上具有更高的能效比和计算效率。

为什么不用GPU？

1. SNN的核心特性之一是其对时间的敏感性，神经元的脉冲是随时间而发生的离散事件。GPU设计用于同时处理大规模的并行计算任务，主要针对的是静态数据和空间并行性
2. GPU虽然在性能上非常强大，但其能效比通常不如专为特定任务设计的硬件。
3. 在SNN中，信息的传播是通过**脉冲**完成的，这意味着计算和通信模式是**高度动态和稀疏**的。GPU的架构并不擅长处理这种稀疏和非均匀的数据通信模式，因为GPU的高效率来自于对**均匀数据的大规模并行处理**。



#### 神经元OS高可用系统开发

##### 意义

SNN和ANN的主要区别：1.信息编码：ANN的信息通过连续的实数值（激活水平）进行编码。而SNN的信息通过脉冲进行编码。脉冲只能是1，信息的传递取决于脉冲的时序和频率。2.时序性：ANN通常使用激活函数来处理信息，激活函数的输出不依赖于时间；SNN处理时间上的离散脉冲，输出依赖于时间。

脉冲神经网络（神经拟态网络）规模较大（一块神经拟态芯片，以Trunorth为例，通常包含百万级别的神经元和上亿级别的突触。而整个脉冲神经网络需要五六十个芯片）。因此需要专门的OS做资源管理和任务划分，映射和调度。

OS的管理将整个神经元系统抽象成节点级，芯片级和簇级。每个簇级节点管理指定的普通节点，存储节点静态元数据信息，训练结果，推理结果。根据该OS结构我们构建了高可用系统。

##### 目前工作

OS负责生成检查点（包括用于恢复的任务检查点以及用于检测错误的状态检查点），由可靠性子系统做故障识别和检查点存储，在遇到故障时匹配对应的处理规则并发送故障通知给OS。并将需要用于恢复的检查点数据回传给OS。

![image-20240107202215183](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20240107202215183.png)



目前做的工作：1.针对常见故障场景，确定了较粗的故障模型。（①在任务执行过程中，任务节点/芯片崩溃 ②在任务执行过程中，簇崩溃。 ③任务执行结束，在节点之间同步状态时，节点崩溃。）

2.构建了容错处理框架，已经搭好框架并和OS联调成功。（在每个芯片上部署一个Agent，用于收集OS的信息。其余高可用系统的部分全部部署在另一台服务器上，用golang语言编写。）

![image.png](https://cdn.nlark.com/yuque/0/2023/png/2938686/1694870966608-00083f97-ede0-48e5-bba9-50566597ebdd.png?x-oss-process=image%2Fresize%2Cw_1237%2Climit_0)

##### 遇到过的问题

①C++和golang之间通过socket通信传输数据包。C++采用小端数据编码，golang采用大端。

②用时序数据库influxdb存储检查点时，influxdb不支持json。将能够识别节点的唯一id属性作为标签存储，提取其余键值对。（InfluxDB 专为处理时序数据而设计，即那些随时间连续记录的数据点。在故障检测系统中，监控数据（如性能指标、日志、事件）通常是时序数据）

##### 项目难点

①检查点粒度。

传统的机器学习框架会在epoch边界处记录检查点，但在大规模训练中，一个epoch的时间较长，中断可能会导致大量计算丢失。随着数据集大小和模型结构的增长，神经网络的epoch时间和整体训练时间也在增加，因此需要动态调整检查点的频率。

平衡低运行时开销与高检查点频率之间的关系，以最小化在任务中断或故障时GPU时间的损失。该框架采用**迭代级别**的检查点设置，提供了**自动确定**何时记录检查点的策略，以及执行成本低且正确的检查点机制。

计划用DNN网络完成。

②高可用系统的精确验证。

硬件不可得，先做一个模拟器，用systemc辅助完成。正在进行模拟器的设计。已经完成对神经元突触的执行硬件模拟和内存结构设计。

![image.png](https://cdn.nlark.com/yuque/0/2023/png/444862/1700228117581-e3cba888-ed91-4bdd-9d89-820c37376c2e.png)

#### 智能网卡卸载分布式文件系统

DFS的 CPU 开销在多租户系统中很大，会影响DFS自身及其它运行应用的性能。将使用RDMA和NVM（PM）的DFS的两个处理密集型操作：复制和发布卸载到智能网卡上，并在其中做流水线设计。

PM分为私有日志区和公有日志区。每个应用进程会链接一个LIBFS节点，将日志先持久化在私有日志区，日志满一个chunk后，发送异步RPC到网卡上的NICFS节点，将数据发布至公有日志区。

发布流水线：1.NICFS收到消息后将chunk获取到网卡内存并验证。 2. 使用主机操作系统中的内核工作线程来启动异步 DMA 进行 chunk 发布（注意这一步在host中进行，因为PCIe发布chunk）3. 延迟会很高。

最后网卡向主机ACK。

复制流水线：1.调用 fsync() 时，主副本 NICFS 获取一块还未被复制的私有日志区条目，并使用复制管道同步复制它们。

2.同步复制时使用**RDMA** 链接来传输日志条目。

3.收到所有副本的ACK后，NICFS发送成功信号给LIBFS。



##### 意义

卸载处理密集型的DFS到智能网卡上，减轻主CPU的负担。

主要是复现SOSP best paper LineFS的工作。

它解决的问题：1.智能网卡作为 PCIe 扩展卡，如何缓解 PCIe 通讯带来的高延迟；2.怎么处理文件系统复杂的数据结构 3.如何利用智能网卡上较少的资源

文件系统分为**LibFS**节点和**NICFS**节点，LibFS 节点位于主机上，被链接到应用进程中（即文件系统客户端），在主机核上运行。NICFS 在智能网卡上。

使用 **ZooKeeper** 作为集群管理器来管理分布式文件系统上的各个节点，并利用它来做错误检测。

LineFS 通过 **RDMA** 来进行**链式复制**操作，通过**更新日志**的方式完成数据同步。

![image-20240107234651022](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20240107234651022.png)

##### 持久化和发布

日志区分为两块：**私有日志区**和**公共日志区**，**LibFS** 模块将数据和元数据的更新持久化到主机的私有持久内存日志中，这些私有日志将异步发布到主机的本地公共持久内存区，并由 NICFS 模块复制到远程持久内存区。

意义：将持久内存延迟关键操作（数据的**初次写入**）和可以稍后执行的操作（**复制到远程持久内存区**的操作）**区分开**

##### 管道并行

当LibFS 日志增长到规定的 chunk 大小时，LibFS 向 NICFS 发送一个 RPC 请求来启动管道。（chunk:环节PCIe带来的高延迟）

###### 发布管道

组成：获取、验证、发布和确认。

当 LibFS 积累到一个 chunk大小的更新后，它向 NICFS 发送一个异步 **RPC** 请求，NICFS 就开始发布这个chunk。

NICFS收到消息后将chunk获取到网卡内存并验证。

使用主机操作系统中的内核工作线程来启动异步 DMA 进行 chunk 发布（注意这一步在host中进行，因为PCIe发布chunk）延迟会很高。

最后网卡向主机ACK。

![image-20240108000343895](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20240108000343895.png)

###### 复制管道

组成：获取、验证、传输和确认

利用fsync（将所有缓冲区数据立即落盘）完成链式复制（个人理解这里应该是修改了fsync函数，可以再确认一下）：沿复制链，每个副本将主服务器的私有日志持久化到自己的本地日志。当主服务器收到所有副本的ACK后fsync返回。

问题：1）RDMA 请求处理延迟。2）文件系统复制操作和共同运行的应用程序之间的 CPU 争夺。

![image-20240108001934657](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20240108001934657.png)

![image-20240108001956596](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20240108001956596.png)

![image-20240108002733089](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20240108002733089.png)

在调用 fsync() 时，主副本 NICFS 获取一块还未被复制的私有日志区条目，并使用复制管道同步复制它们。

同步复制时使用**RDMA** 链接来传输日志条目。

收到所有副本的ACK后，NICFS发送成功信号给LIBFS。

##### 做的工作

复现并改进了**数据复制**和**数据发布**的pipeline。

pipeline改进：在某个pipeline中队列条目超过5个时，新增一个线程协助处理。

###### 复制管道

①在 **fsync 之前**，LibFS 可以以块的粒度来**异步、主动**复制日志条目，fsync 时再**同步复制**所有剩余日志。

###### 发布管道

主机操作系统中使用的内核工作线程来**启动异步 DMA 进行 chunk 发布**（仍然不需要主机core参与）减少因为PCIe发布chunk的高延迟。

##### 被问过的问题

Q：如果客户要读某个数据，DFS是怎样工作的？

A：①客户端通过文件名/标识符，向服务端查询。服务端解析文件名，向元数据服务器查询对应数据所在位置。

②如果有多个副本，根据负载，网络拓扑等选择一个最优服务器，返回。

③客户端从存储节点直接读取数据

④可能涉及校验和等操作，确保在网络传输过程中数据未被破坏。

##### 基础知识

###### 分布式文件系统

文件系统和数据库系统之间的区别：

（1） 存储介质：文件系统用文件将数据长期保存在**外存**上，数据库系统用**数据库**统一存储数据；（数据库比文件系统要快得多，因为**不是每次读写都要落盘**，而是通过**日志**保证一致性）

（2） 程序与数据：文件系统中的**程序和数据**有一定的联系，数据库系统中的程序和数据**分离**；

（3） 数据管理：文件系统用**操作系统**中的存取方法对数据进行管理，数据库系统用**DBMS**统一管理和控制数据；

（4） 存储单位：文件系统实现以**文件**为单位的数据共享，数据库系统实现以**记录和字段**为单位的数据共享。


基本上DFS都采用频繁读写、**从不修改、基本不删除**的策略（用存储空间换高可用、一致性和扩展性）

好处：1. 简化并发控制（一旦写入就不会修改，无需锁和复杂的并发机制）

2. 提高数据可靠性（一旦被成功写入，说明可以保证**副本间的一致性**）
3. 容错性：不用担心版本问题，可以从其它健康节点处恢复数据。

追加优化（Append-only）可以优化写性能（追加写比随机写更快，更简单）

###### RDMA和TCP

RDMA:直接**由硬件解封装**，取出数据后，直接放在应用程序预先指定的内存位置。

由于整个IO过程**无需CPU**参与，**无需**操作系统**内核**参与，**没有系统调用，没有中断**，也**无需内存拷贝**，因此RDMA网络传输可以做到极高的性能。(zero-copy + kernel-by-pass)

**socket API都是同步操作，而RDMA API都是异步操作**

ibv_post_send函数返回成功，仅仅意味着**成功地向网卡提交了发送请求**，并不保证数据真的被发送出去了。如果此时立马对发送数据所在的内存进行写操作，那么发送出去的数据就很可能是不正确的。socket API是同步操作，write函数返回成功，意味着**数据已经被写入了内核缓冲区**。

正确做法：轮询CQ，检查其中的WC，检查该状态是否为成功，成功再返回



**RDMA编程还有一个关键要素，即所有参与发送、接收的数据，所在的内存必须经过注册**。

![img](https://pic1.zhimg.com/80/v2-ea7615096a651042d6ff0758d85ad698_1440w.webp)

使用：

1. Host提交工作请求(WR)到工作队列(WQ): 工作队列包括发送队列(SQ)和接收队列(RQ)。工作队列的每一个元素叫做WQE, 也就是WR。
2. Host从完成队列(CQ）中获取工作完成(WC): 完成队列里的每一个叫做CQE, 也就是WC。
3. 具有RDMA引擎的硬件(hardware)就是一个队列元素处理器。 RDMA硬件不断地从工作队列(WQ)中去取工作请求(WR)来执行，执行完了就给完成队列(CQ)中放置工作完成(WC)。



###### PMEM

也叫NVM。延迟<1us，可以通过CPU指令直接操作，断电后数据不易丢失。

量产的PM目前只有Intel的Optane DC，采用和DRAM一样的DIMM接口。

两种工作模式：Memory Mode和App Direct Mode。

Memory Mode将NVM当作**普通内存**（即**不考虑持久化问题**），将内存当作cache来使用。可以做到**应用无感知**，直接当成一块更大的memory使用。

App Direct Mode 将 Optane DIMMs 当成一个**持久化设备**来使用，直接通过 CPU 指令读写 Optane DIMMs，**不需要经过 DRAM**。应用可以使用能够感知持久化内存的文件系统（比如 EXT4-DAX、XFS-DAX、NOVA）或其他组件（比如 PMDK）来管理、操作持久化内存设备。（但还在Cache里的数据还是有可能丢的）

###### mapreduce

map:切分任务为多份。（切分原则：1.就近。尽量在分配的机器上本身就有备份 2.任务间彼此独立，可并行 3.计算规模被大大缩小）

reduce：汇总结果。

#### 在线画板

完成了一个针对在线会议的多人协作在线画板项目。类似于可视化的在线文档，多名用户可以同时在画板上进行画图、看板排期等操作。

##### 技术

使用**sharedb**来允许多个用户同时对同一图形做编辑和协作。

并用**websocket**来同步json，实现客户端和服务器的实时双向通信。

在前端用**konva**解释json

##### 具体实现

创建websocket连接，用于创建一个sharedb的连接实例。

获取并订阅一个指定的sharedb文档。

##### 部署

用Github Actions（自动化软件部署流程，编译代码并构建docker镜像，将其推送到 Docker Registry，然后在服务器上部署这些镜像。）和Docker实现自动部署。用Nginx处理请求（配置HTTPS证书，正确指向对应的服务端主机。）。

##### 困难和挑战

1. 并发问题：同一个部件（例如看板的某个图形）在同一时间只能由一个用户操作：加锁。
   每个用户分配唯一ID，每个部件记录一个状态：哪个用户正在操作，是否被锁定。
   将这些信息保存在sharedb中进行广播更新。
   当用户开始操作某个部件时：①检查是否上锁②将其锁定为当前用户③完成操作后释放锁。

2. 用户点击批量清空，只能清除本次登录所做的一切修改，其中不包含被他人修改过的图形：每个图形记录一个**最后修改人**。用户批量清空时判断本地缓存的id在sharedb中是否存在，存在是否最后修改人是自己。
3. 如何判断当前画板有哪些在线用户：①登录时记录一次，登出时记录一次。②根据websocket的连接状态，定期检查并更新在线用户

##### 可以优化的地方

绘图事件处理函数应用节流（throttle）或防抖（debounce）技术，以减少不必要的计算和渲染。

### 英文版

Hello, my name is Li Yue. Currently, I am pursuing my master's degree at the School of Software Engineering, Shanghai Jiao Tong University, and I am in my second year. I am expected to graduate in March 2025. I have earned my bachelor degree in Nanjing University, also at the School of Software Engineering, where I ranked in the top 6% of my class in terms of GPA. 

I have had two internship experiences, both in application development. My first internship was at a surveying and mapping company with about thirty to forty employees, where I developed and deployed an Android application for project process advancement and tracking. My second internship was at Microsoft Suzhou Outlook, where I developed and deployed a web-based online drawing board (similar to a graphical online document), mainly responsible for the frontend.

Currently, I am studying at the Scalable and Computational Laboratory at Shanghai Jiao Tong University's Software School. I am involved in a project on a spiking neural network operating system, in collaboration with the Zhejiang Laboratory, where I am responsible for the hardware simulation.

I have experience working with programming languages like C++ and Golang, and I have also done a bit of Android development. My CET-6 score is 590.



